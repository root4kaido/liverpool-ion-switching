{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"my_stacking.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1xHdaEVScrrlj7ttYa6q9lcqpqLInvZ2P","authorship_tag":"ABX9TyPFyMw67gqiLTMA6cnfaNbp"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"vWUJEK1XG-Jy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"02fe6fe6-ea5e-48b7-cfd6-ae920f4d541e","executionInfo":{"status":"ok","timestamp":1590418723024,"user_tz":-540,"elapsed":8871,"user":{"displayName":"にか","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvwEOyMaawSWc32YDQCzWn--PBY05K99EBCYw_mw=s64","userId":"12243319283870198156"}}},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# visualize\n","import matplotlib.pyplot as plt\n","import matplotlib.style as style\n","import seaborn as sns\n","from matplotlib import pyplot\n","from matplotlib.ticker import ScalarFormatter\n","sns.set_context(\"talk\")\n","style.use('fivethirtyeight')\n","from sklearn import metrics\n","from sklearn.metrics import confusion_matrix, f1_score, plot_confusion_matrix\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","from scipy import stats\n","from tqdm import tqdm_notebook as tqdm\n","import os\n","\n","# Any results you write to the current directory are saved as output."],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gaLYu99Cq6KA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jExOx1YMIP99","colab_type":"code","colab":{}},"source":["oof_path = './drive/My Drive/Colab Notebooks/liverpool-ion-switching/data/'\n","sub_path = './drive/My Drive/Colab Notebooks/liverpool-ion-switching/submission/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VekZOyyD2qZO","colab_type":"code","colab":{}},"source":["def reduce_mem_usage(df, verbose=True):\n","    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n","    start_mem = df.memory_usage(deep=True).sum() / 1024 ** 2 # just added \n","    for col in df.columns:\n","        col_type = df[col].dtypes\n","        if col_type in numerics:\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if str(col_type)[:3] == 'int':\n","                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                    df[col] = df[col].astype(np.int8)\n","                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                    df[col] = df[col].astype(np.int16)\n","                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                    df[col] = df[col].astype(np.int32)\n","                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                    df[col] = df[col].astype(np.int64)  \n","            else:\n","                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                    df[col] = df[col].astype(np.float16)\n","                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                    df[col] = df[col].astype(np.float32)\n","                else:\n","                    df[col] = df[col].astype(np.float64)    \n","    end_mem = df.memory_usage(deep=True).sum() / 1024 ** 2\n","    percent = 100 * (start_mem - end_mem) / start_mem\n","    print('Mem. usage decreased from {:5.2f} Mb to {:5.2f} Mb ({:.1f}% reduction)'.format(start_mem, end_mem, percent))\n","    return df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NFWbtAzxI1am","colab_type":"code","colab":{}},"source":["def get_open_channels(file):\n","  df = pd.read_csv(file)\n","  return df['open_channels']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"308mK3KvHLM5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":419},"outputId":"a7fd6e5a-9413-409e-dd07-121595a3c69f","executionInfo":{"status":"ok","timestamp":1590418755353,"user_tz":-540,"elapsed":35231,"user":{"displayName":"にか","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvwEOyMaawSWc32YDQCzWn--PBY05K99EBCYw_mw=s64","userId":"12243319283870198156"}}},"source":["# load submission files\n","oof_df = pd.DataFrame()\n","sub_df = pd.DataFrame()\n","names = ['wavenet_iiyatu',  'lgbm_50hz', 'cat_rem50', 'ridge_rem50', 'xg_rem50', 'wavenet_earlystop']\n","\n","for name in names:\n","  oof_name = 'oof_' + name\n","  oof_df[name] = get_open_channels(oof_path+oof_name+'.csv')\n","  sub_name = 'sub_' + name\n","  sub_df[name] = get_open_channels(sub_path+sub_name+'.csv')\n","\n","sub_df"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>wavenet_iiyatu</th>\n","      <th>lgbm_50hz</th>\n","      <th>cat_rem50</th>\n","      <th>ridge_rem50</th>\n","      <th>xg_rem50</th>\n","      <th>wavenet_earlystop</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1999995</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1999996</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1999997</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1999998</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1999999</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2000000 rows × 6 columns</p>\n","</div>"],"text/plain":["         wavenet_iiyatu  lgbm_50hz  ...  xg_rem50  wavenet_earlystop\n","0                     0          0  ...         0                  0\n","1                     0          0  ...         0                  0\n","2                     0          0  ...         0                  0\n","3                     0          0  ...         0                  0\n","4                     0          0  ...         0                  0\n","...                 ...        ...  ...       ...                ...\n","1999995               0          0  ...         0                  0\n","1999996               0          0  ...         0                  0\n","1999997               0          0  ...         0                  0\n","1999998               0          0  ...         0                  0\n","1999999               0          0  ...         0                  0\n","\n","[2000000 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"QJLwKACEKXha","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"0f3a94c6-6968-40cb-f23d-a3fcd60ad625","executionInfo":{"status":"ok","timestamp":1590418770121,"user_tz":-540,"elapsed":49293,"user":{"displayName":"にか","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvwEOyMaawSWc32YDQCzWn--PBY05K99EBCYw_mw=s64","userId":"12243319283870198156"}}},"source":["  data = pd.read_csv('./drive/My Drive/Colab Notebooks/liverpool-ion-switching/data/train_clean.csv')\n","  y = data[\"open_channels\"]\n","  \n","  for name in oof_df.columns:\n","    f1 = metrics.f1_score(y, oof_df[name], average = 'macro')\n","    # list_score.append(f1)\n","    print(f' {name} oof macro f1 score is {f1}')"],"execution_count":6,"outputs":[{"output_type":"stream","text":[" wavenet_iiyatu oof macro f1 score is 0.9417301168675022\n"," lgbm_50hz oof macro f1 score is 0.9404759460880142\n"," cat_rem50 oof macro f1 score is 0.9405503882061665\n"," ridge_rem50 oof macro f1 score is 0.937621011766118\n"," xg_rem50 oof macro f1 score is 0.9343186300353724\n"," wavenet_earlystop oof macro f1 score is 0.9416549078426217\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZMbUfpyYZr3F","colab_type":"code","colab":{}},"source":["names = ['wavenet_saisin',  'wavenet_4', 'wavenet_5']\n","\n","for name in names:\n","  oof_name = 'oof_' + name\n","  train_proba = np.load(oof_path+oof_name+'.npy')\n","  for i in range(11):\n","    oof_df[f\"{name}_proba_{i}\"] = train_proba[:, i]\n","  sub_name = 'sub_' + name\n","  test_proba = np.load(oof_path+sub_name+'.npy')\n","  for i in range(11):\n","    sub_df[f\"{name}_proba_{i}\"] = test_proba[:, i]\n","\n","Y_train_proba = np.load(oof_path+\"Y_train_proba.npy\")\n","for i in range(11):\n","    oof_df[f\"that_proba_{i}\"] = Y_train_proba[:, i]\n","Y_test_proba = np.load(oof_path+\"Y_test_proba.npy\")\n","for i in range(11):\n","    sub_df[f\"that_proba_{i}\"] = Y_test_proba[:, i]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EfWZKvzZUUET","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":473},"outputId":"df75b5f2-4dfc-464e-fcf0-b838733e22be","executionInfo":{"status":"ok","timestamp":1590418816045,"user_tz":-540,"elapsed":90453,"user":{"displayName":"にか","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvwEOyMaawSWc32YDQCzWn--PBY05K99EBCYw_mw=s64","userId":"12243319283870198156"}}},"source":["oof_df = reduce_mem_usage(oof_df)\n","sub_df = reduce_mem_usage(sub_df)\n","X = oof_df\n","tdf = sub_df\n","X"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Mem. usage decreased from 1907.35 Mb to 448.23 Mb (76.5% reduction)\n","Mem. usage decreased from 762.94 Mb to 179.29 Mb (76.5% reduction)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>wavenet_iiyatu</th>\n","      <th>lgbm_50hz</th>\n","      <th>cat_rem50</th>\n","      <th>ridge_rem50</th>\n","      <th>xg_rem50</th>\n","      <th>wavenet_earlystop</th>\n","      <th>wavenet_saisin_proba_0</th>\n","      <th>wavenet_saisin_proba_1</th>\n","      <th>wavenet_saisin_proba_2</th>\n","      <th>wavenet_saisin_proba_3</th>\n","      <th>wavenet_saisin_proba_4</th>\n","      <th>wavenet_saisin_proba_5</th>\n","      <th>wavenet_saisin_proba_6</th>\n","      <th>wavenet_saisin_proba_7</th>\n","      <th>wavenet_saisin_proba_8</th>\n","      <th>wavenet_saisin_proba_9</th>\n","      <th>wavenet_saisin_proba_10</th>\n","      <th>wavenet_4_proba_0</th>\n","      <th>wavenet_4_proba_1</th>\n","      <th>wavenet_4_proba_2</th>\n","      <th>wavenet_4_proba_3</th>\n","      <th>wavenet_4_proba_4</th>\n","      <th>wavenet_4_proba_5</th>\n","      <th>wavenet_4_proba_6</th>\n","      <th>wavenet_4_proba_7</th>\n","      <th>wavenet_4_proba_8</th>\n","      <th>wavenet_4_proba_9</th>\n","      <th>wavenet_4_proba_10</th>\n","      <th>wavenet_5_proba_0</th>\n","      <th>wavenet_5_proba_1</th>\n","      <th>wavenet_5_proba_2</th>\n","      <th>wavenet_5_proba_3</th>\n","      <th>wavenet_5_proba_4</th>\n","      <th>wavenet_5_proba_5</th>\n","      <th>wavenet_5_proba_6</th>\n","      <th>wavenet_5_proba_7</th>\n","      <th>wavenet_5_proba_8</th>\n","      <th>wavenet_5_proba_9</th>\n","      <th>wavenet_5_proba_10</th>\n","      <th>that_proba_0</th>\n","      <th>that_proba_1</th>\n","      <th>that_proba_2</th>\n","      <th>that_proba_3</th>\n","      <th>that_proba_4</th>\n","      <th>that_proba_5</th>\n","      <th>that_proba_6</th>\n","      <th>that_proba_7</th>\n","      <th>that_proba_8</th>\n","      <th>that_proba_9</th>\n","      <th>that_proba_10</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>9.985352e-01</td>\n","      <td>1.802444e-04</td>\n","      <td>0.000067</td>\n","      <td>1.298189e-04</td>\n","      <td>3.349781e-05</td>\n","      <td>0.000008</td>\n","      <td>0.000018</td>\n","      <td>0.000046</td>\n","      <td>0.000152</td>\n","      <td>0.000421</td>\n","      <td>0.000186</td>\n","      <td>0.998535</td>\n","      <td>7.853508e-04</td>\n","      <td>8.034706e-05</td>\n","      <td>4.571676e-05</td>\n","      <td>1.686811e-05</td>\n","      <td>9.059906e-06</td>\n","      <td>0.000014</td>\n","      <td>3.015995e-05</td>\n","      <td>5.799532e-05</td>\n","      <td>0.000080</td>\n","      <td>0.000218</td>\n","      <td>9.985352e-01</td>\n","      <td>5.455017e-04</td>\n","      <td>3.069639e-05</td>\n","      <td>2.622604e-05</td>\n","      <td>2.503395e-05</td>\n","      <td>2.056360e-05</td>\n","      <td>1.490116e-05</td>\n","      <td>4.768372e-06</td>\n","      <td>0.000023</td>\n","      <td>3.725290e-05</td>\n","      <td>0.000545</td>\n","      <td>0.966797</td>\n","      <td>0.028336</td>\n","      <td>0.004810</td>\n","      <td>0.000114</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>9.985352e-01</td>\n","      <td>7.467270e-04</td>\n","      <td>0.000073</td>\n","      <td>8.410215e-05</td>\n","      <td>1.043081e-05</td>\n","      <td>0.000006</td>\n","      <td>0.000024</td>\n","      <td>0.000030</td>\n","      <td>0.000061</td>\n","      <td>0.000248</td>\n","      <td>0.000186</td>\n","      <td>0.999512</td>\n","      <td>4.370213e-04</td>\n","      <td>3.510714e-05</td>\n","      <td>3.278255e-06</td>\n","      <td>1.460314e-05</td>\n","      <td>2.062321e-05</td>\n","      <td>0.000020</td>\n","      <td>1.889467e-05</td>\n","      <td>3.117323e-05</td>\n","      <td>0.000019</td>\n","      <td>0.000026</td>\n","      <td>9.995117e-01</td>\n","      <td>3.085136e-04</td>\n","      <td>4.351139e-06</td>\n","      <td>3.874302e-06</td>\n","      <td>2.443790e-06</td>\n","      <td>1.668930e-06</td>\n","      <td>1.966953e-06</td>\n","      <td>4.172325e-07</td>\n","      <td>0.000002</td>\n","      <td>3.278255e-06</td>\n","      <td>0.000044</td>\n","      <td>0.996094</td>\n","      <td>0.003466</td>\n","      <td>0.000426</td>\n","      <td>0.000063</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>9.965820e-01</td>\n","      <td>3.112793e-03</td>\n","      <td>0.000010</td>\n","      <td>3.159046e-06</td>\n","      <td>1.847744e-06</td>\n","      <td>0.000004</td>\n","      <td>0.000025</td>\n","      <td>0.000021</td>\n","      <td>0.000011</td>\n","      <td>0.000055</td>\n","      <td>0.000058</td>\n","      <td>0.999512</td>\n","      <td>2.415180e-04</td>\n","      <td>9.644032e-05</td>\n","      <td>6.437302e-06</td>\n","      <td>3.814697e-06</td>\n","      <td>9.834766e-06</td>\n","      <td>0.000024</td>\n","      <td>1.156330e-05</td>\n","      <td>1.168251e-05</td>\n","      <td>0.000008</td>\n","      <td>0.000017</td>\n","      <td>9.892578e-01</td>\n","      <td>8.857727e-03</td>\n","      <td>4.607439e-05</td>\n","      <td>2.131462e-04</td>\n","      <td>1.358986e-03</td>\n","      <td>1.266003e-04</td>\n","      <td>2.026558e-05</td>\n","      <td>1.621246e-05</td>\n","      <td>0.000054</td>\n","      <td>4.667044e-05</td>\n","      <td>0.000204</td>\n","      <td>0.976074</td>\n","      <td>0.018982</td>\n","      <td>0.004677</td>\n","      <td>0.000021</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.000000e+00</td>\n","      <td>3.021955e-05</td>\n","      <td>0.000001</td>\n","      <td>4.172325e-07</td>\n","      <td>8.940697e-07</td>\n","      <td>0.000001</td>\n","      <td>0.000002</td>\n","      <td>0.000001</td>\n","      <td>0.000001</td>\n","      <td>0.000007</td>\n","      <td>0.000009</td>\n","      <td>1.000000</td>\n","      <td>8.523464e-06</td>\n","      <td>1.192093e-06</td>\n","      <td>5.364418e-07</td>\n","      <td>7.152557e-07</td>\n","      <td>2.264977e-06</td>\n","      <td>0.000008</td>\n","      <td>4.589558e-06</td>\n","      <td>4.529953e-06</td>\n","      <td>0.000007</td>\n","      <td>0.000011</td>\n","      <td>1.000000e+00</td>\n","      <td>2.920628e-06</td>\n","      <td>4.768372e-07</td>\n","      <td>3.159046e-06</td>\n","      <td>6.556511e-07</td>\n","      <td>1.192093e-07</td>\n","      <td>3.576279e-07</td>\n","      <td>1.788139e-07</td>\n","      <td>0.000001</td>\n","      <td>5.364418e-07</td>\n","      <td>0.000003</td>\n","      <td>0.996094</td>\n","      <td>0.003626</td>\n","      <td>0.000326</td>\n","      <td>0.000046</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.000000e+00</td>\n","      <td>3.272295e-05</td>\n","      <td>0.000001</td>\n","      <td>2.980232e-07</td>\n","      <td>1.907349e-06</td>\n","      <td>0.000005</td>\n","      <td>0.000004</td>\n","      <td>0.000001</td>\n","      <td>0.000002</td>\n","      <td>0.000008</td>\n","      <td>0.000017</td>\n","      <td>1.000000</td>\n","      <td>5.364418e-07</td>\n","      <td>1.788139e-07</td>\n","      <td>2.980232e-07</td>\n","      <td>2.980232e-07</td>\n","      <td>8.344650e-07</td>\n","      <td>0.000002</td>\n","      <td>8.940697e-07</td>\n","      <td>8.940697e-07</td>\n","      <td>0.000001</td>\n","      <td>0.000002</td>\n","      <td>1.000000e+00</td>\n","      <td>4.768372e-07</td>\n","      <td>7.748604e-07</td>\n","      <td>8.225441e-06</td>\n","      <td>7.987022e-06</td>\n","      <td>6.556511e-07</td>\n","      <td>2.384186e-06</td>\n","      <td>4.768372e-07</td>\n","      <td>0.000002</td>\n","      <td>1.728535e-06</td>\n","      <td>0.000010</td>\n","      <td>0.997559</td>\n","      <td>0.002335</td>\n","      <td>0.000158</td>\n","      <td>0.000042</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4999995</th>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>7.331371e-06</td>\n","      <td>8.344650e-07</td>\n","      <td>0.000021</td>\n","      <td>2.193451e-05</td>\n","      <td>2.384186e-07</td>\n","      <td>0.000056</td>\n","      <td>0.002735</td>\n","      <td>0.986816</td>\n","      <td>0.010345</td>\n","      <td>0.000013</td>\n","      <td>0.000010</td>\n","      <td>0.000003</td>\n","      <td>1.355410e-04</td>\n","      <td>1.710653e-05</td>\n","      <td>2.980232e-07</td>\n","      <td>4.768372e-07</td>\n","      <td>2.920628e-06</td>\n","      <td>0.005470</td>\n","      <td>9.838867e-01</td>\n","      <td>1.055908e-02</td>\n","      <td>0.000063</td>\n","      <td>0.000011</td>\n","      <td>2.384186e-07</td>\n","      <td>9.834766e-06</td>\n","      <td>1.370907e-06</td>\n","      <td>1.907349e-06</td>\n","      <td>3.039837e-06</td>\n","      <td>2.348423e-05</td>\n","      <td>2.059937e-02</td>\n","      <td>9.770508e-01</td>\n","      <td>0.002201</td>\n","      <td>2.235174e-05</td>\n","      <td>0.000009</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.003376</td>\n","      <td>0.078369</td>\n","      <td>0.867188</td>\n","      <td>0.048370</td>\n","      <td>0.002733</td>\n","      <td>0.000172</td>\n","    </tr>\n","    <tr>\n","      <th>4999996</th>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>6.675720e-06</td>\n","      <td>1.549721e-06</td>\n","      <td>0.000014</td>\n","      <td>3.874302e-06</td>\n","      <td>2.384186e-07</td>\n","      <td>0.000426</td>\n","      <td>0.087158</td>\n","      <td>0.911621</td>\n","      <td>0.000825</td>\n","      <td>0.000008</td>\n","      <td>0.000025</td>\n","      <td>0.000041</td>\n","      <td>3.442764e-04</td>\n","      <td>1.728535e-05</td>\n","      <td>7.450581e-06</td>\n","      <td>1.436472e-05</td>\n","      <td>1.801252e-04</td>\n","      <td>0.040039</td>\n","      <td>9.536133e-01</td>\n","      <td>5.229950e-03</td>\n","      <td>0.000194</td>\n","      <td>0.000086</td>\n","      <td>2.980232e-07</td>\n","      <td>2.980232e-05</td>\n","      <td>8.940697e-07</td>\n","      <td>7.748604e-07</td>\n","      <td>1.907349e-06</td>\n","      <td>9.000301e-06</td>\n","      <td>3.378296e-02</td>\n","      <td>9.653320e-01</td>\n","      <td>0.000630</td>\n","      <td>1.990795e-05</td>\n","      <td>0.000009</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000033</td>\n","      <td>0.000813</td>\n","      <td>0.111206</td>\n","      <td>0.832031</td>\n","      <td>0.053162</td>\n","      <td>0.002451</td>\n","      <td>0.000095</td>\n","    </tr>\n","    <tr>\n","      <th>4999997</th>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>3.576279e-06</td>\n","      <td>1.490116e-06</td>\n","      <td>0.000024</td>\n","      <td>5.525351e-05</td>\n","      <td>1.668930e-06</td>\n","      <td>0.000009</td>\n","      <td>0.000007</td>\n","      <td>0.003557</td>\n","      <td>0.961914</td>\n","      <td>0.033875</td>\n","      <td>0.000445</td>\n","      <td>0.000051</td>\n","      <td>2.322197e-04</td>\n","      <td>1.347065e-05</td>\n","      <td>3.039837e-04</td>\n","      <td>1.427650e-03</td>\n","      <td>4.401207e-04</td>\n","      <td>0.000057</td>\n","      <td>4.550934e-03</td>\n","      <td>8.447266e-01</td>\n","      <td>0.134155</td>\n","      <td>0.013817</td>\n","      <td>1.206398e-04</td>\n","      <td>1.668930e-06</td>\n","      <td>1.192093e-07</td>\n","      <td>9.417534e-06</td>\n","      <td>1.106858e-04</td>\n","      <td>3.421307e-05</td>\n","      <td>4.798174e-05</td>\n","      <td>2.910614e-03</td>\n","      <td>0.958984</td>\n","      <td>3.741455e-02</td>\n","      <td>0.000274</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.004055</td>\n","      <td>0.000656</td>\n","      <td>0.075256</td>\n","      <td>0.861816</td>\n","      <td>0.053680</td>\n","      <td>0.004509</td>\n","    </tr>\n","    <tr>\n","      <th>4999998</th>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>2.384186e-07</td>\n","      <td>1.394749e-05</td>\n","      <td>0.000443</td>\n","      <td>1.317263e-04</td>\n","      <td>2.672672e-04</td>\n","      <td>0.000163</td>\n","      <td>0.000020</td>\n","      <td>0.000066</td>\n","      <td>0.068054</td>\n","      <td>0.916992</td>\n","      <td>0.013710</td>\n","      <td>0.000094</td>\n","      <td>7.838011e-05</td>\n","      <td>3.397465e-06</td>\n","      <td>2.219677e-04</td>\n","      <td>6.890297e-04</td>\n","      <td>8.449554e-04</td>\n","      <td>0.000147</td>\n","      <td>2.189636e-03</td>\n","      <td>1.083984e-01</td>\n","      <td>0.808594</td>\n","      <td>0.078491</td>\n","      <td>4.744530e-04</td>\n","      <td>4.971027e-05</td>\n","      <td>9.298325e-06</td>\n","      <td>1.240969e-04</td>\n","      <td>2.729893e-04</td>\n","      <td>1.577139e-04</td>\n","      <td>3.075600e-04</td>\n","      <td>1.985550e-03</td>\n","      <td>0.135254</td>\n","      <td>8.457031e-01</td>\n","      <td>0.015564</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000125</td>\n","      <td>0.000965</td>\n","      <td>0.020721</td>\n","      <td>0.209351</td>\n","      <td>0.701660</td>\n","      <td>0.067322</td>\n","    </tr>\n","    <tr>\n","      <th>4999999</th>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>9</td>\n","      <td>2.354383e-05</td>\n","      <td>8.159876e-05</td>\n","      <td>0.000854</td>\n","      <td>9.841919e-04</td>\n","      <td>2.510071e-03</td>\n","      <td>0.019211</td>\n","      <td>0.002111</td>\n","      <td>0.005592</td>\n","      <td>0.175781</td>\n","      <td>0.591309</td>\n","      <td>0.201538</td>\n","      <td>0.000349</td>\n","      <td>5.130768e-04</td>\n","      <td>5.573034e-05</td>\n","      <td>9.691715e-05</td>\n","      <td>1.367331e-04</td>\n","      <td>7.539988e-05</td>\n","      <td>0.000198</td>\n","      <td>2.366638e-02</td>\n","      <td>5.014648e-01</td>\n","      <td>0.465820</td>\n","      <td>0.007378</td>\n","      <td>1.149178e-03</td>\n","      <td>6.300211e-05</td>\n","      <td>4.059076e-05</td>\n","      <td>8.263588e-04</td>\n","      <td>6.566048e-04</td>\n","      <td>1.635551e-03</td>\n","      <td>1.264572e-03</td>\n","      <td>1.432037e-02</td>\n","      <td>0.528809</td>\n","      <td>4.208984e-01</td>\n","      <td>0.030548</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000017</td>\n","      <td>0.002060</td>\n","      <td>0.000563</td>\n","      <td>0.003481</td>\n","      <td>0.016357</td>\n","      <td>0.086182</td>\n","      <td>0.355469</td>\n","      <td>0.481689</td>\n","      <td>0.053986</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000000 rows × 50 columns</p>\n","</div>"],"text/plain":["         wavenet_iiyatu  lgbm_50hz  ...  that_proba_9  that_proba_10\n","0                     0          0  ...      0.000000       0.000000\n","1                     0          0  ...      0.000000       0.000000\n","2                     0          0  ...      0.000000       0.000000\n","3                     0          0  ...      0.000000       0.000000\n","4                     0          0  ...      0.000000       0.000000\n","...                 ...        ...  ...           ...            ...\n","4999995               7          7  ...      0.002733       0.000172\n","4999996               7          7  ...      0.002451       0.000095\n","4999997               8          8  ...      0.053680       0.004509\n","4999998               9          9  ...      0.701660       0.067322\n","4999999               9          9  ...      0.481689       0.053986\n","\n","[5000000 rows x 50 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"s8fv4fNfKkqo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":544},"outputId":"54ccfd8e-760b-4567-9bc8-3a79bcba775d","executionInfo":{"status":"ok","timestamp":1590419943533,"user_tz":-540,"elapsed":1216796,"user":{"displayName":"にか","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvwEOyMaawSWc32YDQCzWn--PBY05K99EBCYw_mw=s64","userId":"12243319283870198156"}}},"source":["\n","from sklearn.model_selection import StratifiedKFold\n","import lightgbm as lgb\n","from sklearn import metrics\n","i=1;\n","n_fold = 5 # amount of data folds\n","folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n","scores = []\n","prediction = np.zeros(shape=(tdf.shape[0],1))\n","\n","params = {'boosting_type': 'gbdt',\n","          'metric': 'rmse',\n","          'objective': 'regression',\n","          'n_jobs': -1,\n","          'seed': 236}\n","          # 'num_leaves': 280,\n","          # 'learning_rate': 0.026623466966581126,\n","          # 'max_depth': 73,\n","          # 'lambda_l1': 2.959759088169741,\n","          # 'lambda_l2': 1.331172832164913,\n","          # 'bagging_fraction': 0.9655406551472153,\n","          # 'bagging_freq': 9,\n","          # 'colsample_bytree': 0.6867118652742716}\n","\n","oof_pred = np.zeros(len(X))\n","# y_pred = np.zeros(shape=(tdf.shape[0], 1))\n","y_pred = []\n","train_pred = []\n","\n","for fold_n, (train_index, valid_index) in enumerate(folds.split(X,y)):\n","    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index] # train and validation data splits\n","    y_train, y_valid = y[train_index], y[valid_index]\n","    X_train = X_train.values\n","    X_valid = X_valid.values\n","    train_set = lgb.Dataset(X_train, y_train)\n","    val_set = lgb.Dataset(X_valid, y_valid)\n","    \n","    model = lgb.train(params, train_set, num_boost_round = 5000, early_stopping_rounds = 100, \n","                      valid_sets = [train_set, val_set], verbose_eval = 100)\n","    \n","    oof_pred[valid_index] = model.predict(X_valid)\n","    # y_pred += model.predict(tdf) / folds.n_splits\n","    y_pred.append(model.predict(tdf))\n","    train_pred.append(model.predict(X))\n","    # break\n","    \n","rmse_score = np.sqrt(metrics.mean_squared_error(y, oof_pred))\n","# want to clip and then round predictions (you can get a better performance using optimization to found the best cuts)\n","oof_pred = np.round(np.clip(oof_pred, 0, 10)).astype(int)\n","round_y_pred = np.round(np.clip(y_pred, 0, 10)).astype(int)\n","f1 = metrics.f1_score(y, oof_pred, average = 'macro')\n","print(f'Our oof rmse score is {rmse_score}')\n","print(f'Our oof macro f1 score is {f1}')\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Training until validation scores don't improve for 100 rounds.\n","[100]\ttraining's rmse: 0.145761\tvalid_1's rmse: 0.146378\n","[200]\ttraining's rmse: 0.145014\tvalid_1's rmse: 0.14635\n","[300]\ttraining's rmse: 0.144321\tvalid_1's rmse: 0.146331\n","Early stopping, best iteration is:\n","[274]\ttraining's rmse: 0.144497\tvalid_1's rmse: 0.146326\n","Training until validation scores don't improve for 100 rounds.\n","[100]\ttraining's rmse: 0.145822\tvalid_1's rmse: 0.145984\n","[200]\ttraining's rmse: 0.145105\tvalid_1's rmse: 0.145976\n","[300]\ttraining's rmse: 0.144438\tvalid_1's rmse: 0.145979\n","Early stopping, best iteration is:\n","[247]\ttraining's rmse: 0.144778\tvalid_1's rmse: 0.145967\n","Training until validation scores don't improve for 100 rounds.\n","[100]\ttraining's rmse: 0.145658\tvalid_1's rmse: 0.146682\n","[200]\ttraining's rmse: 0.144928\tvalid_1's rmse: 0.146654\n","Early stopping, best iteration is:\n","[172]\ttraining's rmse: 0.145109\tvalid_1's rmse: 0.14665\n","Training until validation scores don't improve for 100 rounds.\n","[100]\ttraining's rmse: 0.14575\tvalid_1's rmse: 0.146302\n","[200]\ttraining's rmse: 0.145012\tvalid_1's rmse: 0.146293\n","[300]\ttraining's rmse: 0.14435\tvalid_1's rmse: 0.146291\n","Early stopping, best iteration is:\n","[285]\ttraining's rmse: 0.144443\tvalid_1's rmse: 0.146286\n","Training until validation scores don't improve for 100 rounds.\n","[100]\ttraining's rmse: 0.145683\tvalid_1's rmse: 0.146542\n","[200]\ttraining's rmse: 0.144932\tvalid_1's rmse: 0.146512\n","[300]\ttraining's rmse: 0.144275\tvalid_1's rmse: 0.146525\n","Early stopping, best iteration is:\n","[203]\ttraining's rmse: 0.144905\tvalid_1's rmse: 0.146506\n","Our oof rmse score is 0.1463475315935492\n","Our oof macro f1 score is 0.942228107422708\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"22f6L7r7oJL3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":669},"outputId":"a4847558-2324-407c-dd1a-7ea5ca3a3535","executionInfo":{"status":"ok","timestamp":1590421276176,"user_tz":-540,"elapsed":9039,"user":{"displayName":"にか","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvwEOyMaawSWc32YDQCzWn--PBY05K99EBCYw_mw=s64","userId":"12243319283870198156"}}},"source":["\n","for i in range(len(y_pred)):\n","  if i == 0:\n","    predpred = y_pred[i] / folds.n_splits\n","  else:\n","    predpred += y_pred[i] / folds.n_splits\n","\n","round_y_pred = np.round(np.clip(predpred, 0, 10)).astype(int)\n","\n","submission = pd.read_csv('./drive/My Drive/Colab Notebooks/liverpool-ion-switching/submission/sample_submission.csv')\n","\n","submission['open_channels'] = round_y_pred\n","submission.to_csv('./drive/My Drive/Colab Notebooks/liverpool-ion-switching/sub_9422_wav.csv', index = False, float_format='%.4f')\n","submission.head(20)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>time</th>\n","      <th>open_channels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>500.0001</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>500.0002</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>500.0003</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>500.0004</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>500.0005</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>500.0006</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>500.0007</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>500.0008</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>500.0009</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>500.0010</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>500.0011</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>500.0012</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>500.0013</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>500.0014</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>500.0015</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>500.0016</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>500.0017</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>500.0018</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>500.0019</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>500.0020</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        time  open_channels\n","0   500.0001              0\n","1   500.0002              0\n","2   500.0003              0\n","3   500.0004              0\n","4   500.0005              0\n","5   500.0006              0\n","6   500.0007              0\n","7   500.0008              0\n","8   500.0009              0\n","9   500.0010              0\n","10  500.0011              0\n","11  500.0012              0\n","12  500.0013              0\n","13  500.0014              0\n","14  500.0015              0\n","15  500.0016              0\n","16  500.0017              0\n","17  500.0018              0\n","18  500.0019              0\n","19  500.0020              0"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"6br2cnNZUYWh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":853},"outputId":"ccaf24ca-4588-43bf-e5a5-e38ff6b0c8c6","executionInfo":{"status":"ok","timestamp":1590393943965,"user_tz":-540,"elapsed":125600,"user":{"displayName":"にか","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvwEOyMaawSWc32YDQCzWn--PBY05K99EBCYw_mw=s64","userId":"12243319283870198156"}}},"source":["!pip install tensorflow==1.14\n","from keras.models import Model\n","import keras.layers as L\n","import tensorflow as tf\n","tf.__version__"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow==1.14 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.29.0)\n","Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.4)\n","Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (46.3.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.1.0)\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["'1.14.0'"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"NLbB4n7icZOh","colab_type":"code","colab":{}},"source":["def create_mpl(shape):\n","    '''\n","    Returns a keras model\n","    '''\n","    \n","    X_input = L.Input(shape)\n","    \n","    X = L.Dense(150, activation='relu')(X_input)\n","    X = L.Dense(150, activation='relu')(X)\n","    X = L.Dense(125, activation='relu')(X)\n","    X = L.Dense(100, activation='relu')(X)\n","    X = L.Dense(75, activation='relu')(X)\n","    X = L.Dense(50, activation='relu')(X)\n","    X = L.Dense(25, activation='relu')(X)\n","    X = L.Dense(11, activation='softmax')(X)\n","\n","    # X = L.Dense(150, activation='LeakyReLU')(X_input)\n","    # X = L.Dense(150, activation='LeakyReLU')(X)\n","    # X = L.Dense(125, activation='LeakyReLU')(X)\n","    # X = L.Dense(75, activation='LeakyReLU')(X)\n","    # X = L.Dense(50, activation='LeakyReLU')(X)\n","    # X = L.Dense(25, activation='LeakyReLU')(X)\n","    # X = L.Dense(11, activation='softmax')(X)\n","    \n","    model = Model(inputs=X_input, outputs=X)\n","    \n","    return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eb8npH6eDGTr","colab_type":"code","colab":{}},"source":["def f1_score_calc(y_true, y_pred):\n","    return f1_score(y_true, y_pred, average=\"macro\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bagORoDLd4p6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":625},"outputId":"fc36fd41-68f1-4a75-994f-c05b5e537460","executionInfo":{"status":"ok","timestamp":1590393944488,"user_tz":-540,"elapsed":123923,"user":{"displayName":"にか","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvwEOyMaawSWc32YDQCzWn--PBY05K99EBCYw_mw=s64","userId":"12243319283870198156"}}},"source":["def get_class_weight(classes, exp=1):\n","    '''\n","    Weight of the class is inversely proportional to the population of the class.\n","    There is an exponent for adding more weight.\n","    '''\n","    hist, _ = np.histogram(classes, bins=np.arange(12)-0.5)\n","    class_weight = hist.sum()/np.power(hist, exp)\n","    \n","    return class_weight\n","\n","class_weight = get_class_weight(y)\n","print('class_weight=', class_weight)\n","plt.figure()\n","plt.title('classes')\n","plt.hist(y, bins=np.arange(12)-0.5)\n","plt.figure()\n","plt.title('class_weight')\n","plt.bar(np.arange(11), class_weight)\n","plt.title('class_weight')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["class_weight= [  4.03176385   5.07168831   9.02650905   7.47821223  12.39433827\n","  17.9935727   26.57990984  18.86685659  20.39293099  36.73229503\n"," 139.92667842]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 1.0, 'class_weight')"]},"metadata":{"tags":[]},"execution_count":12},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"afsiD8M9ccM3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"5f602263-ddce-4272-ace1-e40ce5c79ed8","executionInfo":{"status":"ok","timestamp":1590408186962,"user_tz":-540,"elapsed":12208631,"user":{"displayName":"にか","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvwEOyMaawSWc32YDQCzWn--PBY05K99EBCYw_mw=s64","userId":"12243319283870198156"}}},"source":["from sklearn.model_selection import StratifiedKFold\n","i=1;\n","n_fold = 4 # amount of data folds\n","folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=17)\n","scores = []\n","oof_pred = np.zeros((len(X), 11))\n","\n","prediction = np.zeros(shape=(tdf.shape[0],11))\n","for fold_n, (train_index, valid_index) in enumerate(folds.split(X,y)):\n","    print(i,\"*******th fold**************\")\n","    \n","    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index] # train and validation data splits\n","    y_train, y_valid = y[train_index], y[valid_index]\n","    X_train = X_train.values\n","    X_valid = X_valid.values\n","    mlp = create_mpl(X_train[0].shape)\n","    mlp.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n","    mlp.fit(x=X_train, y=y_train, epochs=50, batch_size=1024, class_weight=class_weight)\n","    pred = mlp.predict(X_valid)\n","    oof_pred[valid_index] = pred\n","    pred = np.argmax(pred,axis=-1)\n","    score = f1_score_calc(y_valid, pred)\n","    print(score)\n","    #scores.append(score)\n","    y_pred = mlp.predict(tdf) \n","    prediction += y_pred\n","    i = i+1\n","\n","prediction /= n_fold\n","#print('CV mean: {:.4f}, CV std: {:.4f}'.format(np.mean(scores), np.std(scores)))\n","\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["1 *******th fold**************\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Epoch 1/50\n","3750000/3750000 [==============================] - 72s 19us/step - loss: 0.0949 - sparse_categorical_accuracy: 0.9690\n","Epoch 2/50\n","3750000/3750000 [==============================] - 73s 20us/step - loss: 0.0786 - sparse_categorical_accuracy: 0.9709\n","Epoch 3/50\n","3750000/3750000 [==============================] - 74s 20us/step - loss: 0.0774 - sparse_categorical_accuracy: 0.9710\n","Epoch 4/50\n","3750000/3750000 [==============================] - 73s 19us/step - loss: 0.0768 - sparse_categorical_accuracy: 0.9711\n","Epoch 5/50\n","3750000/3750000 [==============================] - 74s 20us/step - loss: 0.0765 - sparse_categorical_accuracy: 0.9711\n","Epoch 6/50\n","3750000/3750000 [==============================] - 74s 20us/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9712\n","Epoch 7/50\n","3750000/3750000 [==============================] - 72s 19us/step - loss: 0.0760 - sparse_categorical_accuracy: 0.9712\n","Epoch 8/50\n","3750000/3750000 [==============================] - 72s 19us/step - loss: 0.0758 - sparse_categorical_accuracy: 0.9712\n","Epoch 9/50\n","3750000/3750000 [==============================] - 72s 19us/step - loss: 0.0757 - sparse_categorical_accuracy: 0.9713\n","Epoch 10/50\n","3750000/3750000 [==============================] - 73s 19us/step - loss: 0.0756 - sparse_categorical_accuracy: 0.9713\n","Epoch 11/50\n","3750000/3750000 [==============================] - 73s 20us/step - loss: 0.0755 - sparse_categorical_accuracy: 0.9713\n","Epoch 12/50\n","3750000/3750000 [==============================] - 73s 20us/step - loss: 0.0755 - sparse_categorical_accuracy: 0.9713\n","Epoch 13/50\n","3750000/3750000 [==============================] - 72s 19us/step - loss: 0.0754 - sparse_categorical_accuracy: 0.9713\n","Epoch 14/50\n","3750000/3750000 [==============================] - 73s 19us/step - loss: 0.0753 - sparse_categorical_accuracy: 0.9713\n","Epoch 15/50\n","3750000/3750000 [==============================] - 73s 19us/step - loss: 0.0753 - sparse_categorical_accuracy: 0.9713\n","Epoch 16/50\n","3750000/3750000 [==============================] - 72s 19us/step - loss: 0.0753 - sparse_categorical_accuracy: 0.9713\n","Epoch 17/50\n","3750000/3750000 [==============================] - 73s 19us/step - loss: 0.0752 - sparse_categorical_accuracy: 0.9713\n","Epoch 18/50\n","3750000/3750000 [==============================] - 73s 19us/step - loss: 0.0752 - sparse_categorical_accuracy: 0.9714\n","Epoch 19/50\n","3750000/3750000 [==============================] - 73s 19us/step - loss: 0.0751 - sparse_categorical_accuracy: 0.9714\n","Epoch 20/50\n","3750000/3750000 [==============================] - 73s 19us/step - loss: 0.0751 - sparse_categorical_accuracy: 0.9714\n","Epoch 21/50\n","3750000/3750000 [==============================] - 74s 20us/step - loss: 0.0751 - sparse_categorical_accuracy: 0.9714\n","Epoch 22/50\n","3750000/3750000 [==============================] - 73s 20us/step - loss: 0.0750 - sparse_categorical_accuracy: 0.9714\n","Epoch 23/50\n","3750000/3750000 [==============================] - 74s 20us/step - loss: 0.0750 - sparse_categorical_accuracy: 0.9714\n","Epoch 24/50\n","3750000/3750000 [==============================] - 72s 19us/step - loss: 0.0750 - sparse_categorical_accuracy: 0.9714\n","Epoch 25/50\n","3750000/3750000 [==============================] - 72s 19us/step - loss: 0.0750 - sparse_categorical_accuracy: 0.9714\n","Epoch 26/50\n","3750000/3750000 [==============================] - 72s 19us/step - loss: 0.0750 - sparse_categorical_accuracy: 0.9714\n","Epoch 27/50\n","3750000/3750000 [==============================] - 73s 19us/step - loss: 0.0750 - sparse_categorical_accuracy: 0.9714\n","Epoch 28/50\n","3750000/3750000 [==============================] - 73s 20us/step - loss: 0.0749 - sparse_categorical_accuracy: 0.9714\n","Epoch 29/50\n","3750000/3750000 [==============================] - 70s 19us/step - loss: 0.0749 - sparse_categorical_accuracy: 0.9714\n","Epoch 30/50\n","3750000/3750000 [==============================] - 70s 19us/step - loss: 0.0749 - sparse_categorical_accuracy: 0.9714\n","Epoch 31/50\n","3750000/3750000 [==============================] - 69s 18us/step - loss: 0.0749 - sparse_categorical_accuracy: 0.9714\n","Epoch 32/50\n","3750000/3750000 [==============================] - 69s 18us/step - loss: 0.0751 - sparse_categorical_accuracy: 0.9714\n","Epoch 33/50\n","3750000/3750000 [==============================] - 73s 19us/step - loss: 0.0748 - sparse_categorical_accuracy: 0.9714\n","Epoch 34/50\n","3750000/3750000 [==============================] - 69s 19us/step - loss: 0.0748 - sparse_categorical_accuracy: 0.9714\n","Epoch 35/50\n","3750000/3750000 [==============================] - 71s 19us/step - loss: 0.0748 - sparse_categorical_accuracy: 0.9714\n","Epoch 36/50\n","3750000/3750000 [==============================] - 70s 19us/step - loss: 0.0748 - sparse_categorical_accuracy: 0.9714\n","Epoch 37/50\n","3750000/3750000 [==============================] - 70s 19us/step - loss: 0.0748 - sparse_categorical_accuracy: 0.9714\n","Epoch 38/50\n","3750000/3750000 [==============================] - 70s 19us/step - loss: 0.0747 - sparse_categorical_accuracy: 0.9714\n","Epoch 39/50\n","3750000/3750000 [==============================] - 70s 19us/step - loss: 0.0748 - sparse_categorical_accuracy: 0.9714\n","Epoch 40/50\n","3750000/3750000 [==============================] - 70s 19us/step - loss: 0.0747 - sparse_categorical_accuracy: 0.9714\n","Epoch 41/50\n","3750000/3750000 [==============================] - 70s 19us/step - loss: 0.0747 - sparse_categorical_accuracy: 0.9714\n","Epoch 42/50\n","3750000/3750000 [==============================] - 71s 19us/step - loss: 0.0747 - sparse_categorical_accuracy: 0.9714\n","Epoch 43/50\n","3750000/3750000 [==============================] - 70s 19us/step - loss: 0.0747 - sparse_categorical_accuracy: 0.9714\n","Epoch 44/50\n","1797120/3750000 [=============>................] - ETA: 36s - loss: 0.0748 - sparse_categorical_accuracy: 0.9713Buffered data was truncated after reaching the output size limit."],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HeEUYCAFcmVD","colab_type":"code","colab":{}},"source":["np.save('./drive/My Drive/Colab Notebooks/liverpool-ion-switching/data/oof_mlp_proba_scoreing.npy', oof_pred)\n","for i in range(len(y_pred)):\n","  if(i==0):\n","    round_y_pred = y_pred[i]\n","  else:\n","    round_y_pred += y_pred[i]\n","np.save('./drive/My Drive/Colab Notebooks/liverpool-ion-switching/data/sub_mlp_proba_scoreing.npy', round_y_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N0ln0reNP2YU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"321b7804-b4c5-4977-a93d-4c03a681f994","executionInfo":{"status":"ok","timestamp":1590408189189,"user_tz":-540,"elapsed":7233238,"user":{"displayName":"にか","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvwEOyMaawSWc32YDQCzWn--PBY05K99EBCYw_mw=s64","userId":"12243319283870198156"}}},"source":["f1 = metrics.f1_score(y, np.argmax(oof_pred, axis=-1), average = 'macro')\n","f1"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9420867826857738"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"zDl-LG-Dcz74","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":359},"outputId":"0127fa01-bb75-4cf9-d864-42a47c176848","executionInfo":{"status":"ok","timestamp":1590333160380,"user_tz":-540,"elapsed":21028,"user":{"displayName":"にか","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvwEOyMaawSWc32YDQCzWn--PBY05K99EBCYw_mw=s64","userId":"12243319283870198156"}}},"source":["sub = pd.read_csv('./drive/My Drive/Colab Notebooks/liverpool-ion-switching/submission/sample_submission.csv')\n","sub['open_channels'] =  np.argmax(round_y_pred, axis=-1)\n","\n","sub.to_csv('./drive/My Drive/Colab Notebooks/liverpool-ion-switching/submission/scoreing_mlp.csv', index=False, float_format='%.4f')\n","sub.head(10)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>time</th>\n","      <th>open_channels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>500.0001</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>500.0002</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>500.0003</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>500.0004</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>500.0005</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>500.0006</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>500.0007</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>500.0008</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>500.0009</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>500.0010</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       time  open_channels\n","0  500.0001              0\n","1  500.0002              0\n","2  500.0003              0\n","3  500.0004              0\n","4  500.0005              0\n","5  500.0006              0\n","6  500.0007              0\n","7  500.0008              0\n","8  500.0009              0\n","9  500.0010              0"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"2oHyrL92dDeJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"52f6a3b5-5588-48c8-eb8a-953d6f5a3269","executionInfo":{"status":"ok","timestamp":1590390684566,"user_tz":-540,"elapsed":6513039,"user":{"displayName":"にか","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvwEOyMaawSWc32YDQCzWn--PBY05K99EBCYw_mw=s64","userId":"12243319283870198156"}}},"source":["\n","from sklearn.model_selection import StratifiedKFold\n","import lightgbm as lgb\n","from sklearn import metrics\n","i=1;\n","n_fold = 5 # amount of data folds\n","folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n","scores = []\n","prediction = np.zeros(shape=(tdf.shape[0],1))\n","\n","# params = {'boosting_type': 'gbdt',\n","#           'metric': 'rmse',\n","#           'objective': 'regression',\n","#           'n_jobs': -1,\n","#           'seed': 236}\n","#           # 'num_leaves': 280,\n","#           # 'learning_rate': 0.026623466966581126,\n","#           # 'max_depth': 73,\n","#           # 'lambda_l1': 2.959759088169741,\n","#           # 'lambda_l2': 1.331172832164913,\n","#           # 'bagging_fraction': 0.9655406551472153,\n","#           # 'bagging_freq': 9,\n","#           # 'colsample_bytree': 0.6867118652742716}\n","\n","params = {\n","    'objective': 'multiclass',\n","    'num_class': 11,\n","    'metric': 'multi_logloss'}\n","    # 'learning_rate': 0.00987173774816051,\n","    # 'lambda_l1': 0.00031963798315506463,\n","    # 'lambda_l2': 0.18977456778807847,\n","    # 'num_leaves': 171, \n","    # 'feature_fraction': 0.58733782457345, \n","    # 'bagging_fraction': 0.7057826081907392, \n","    # 'bagging_freq': 4}\n","\n","oof_pred = np.zeros((len(X), 11))\n","# y_pred = np.zeros(shape=(tdf.shape[0], 1))\n","y_pred = []\n","train_pred = []\n","\n","for fold_n, (train_index, valid_index) in enumerate(folds.split(X,y)):\n","    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index] # train and validation data splits\n","    y_train, y_valid = y[train_index], y[valid_index]\n","    X_train = X_train.values\n","    X_valid = X_valid.values\n","    train_set = lgb.Dataset(X_train, y_train)\n","    val_set = lgb.Dataset(X_valid, y_valid)\n","    \n","    model = lgb.train(params, train_set, num_boost_round = 500, early_stopping_rounds = 30, \n","                      valid_sets = [train_set, val_set], verbose_eval = 10)\n","    \n","    # oof_pred[valid_index] = model.predict(X_valid)\n","    gbc_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n","    oof_pred[valid_index] = gbc_pred\n","    # y_pred += model.predict(tdf) / folds.n_splits\n","    print(f1_score(y_valid, np.argmax(gbc_pred, axis=1), average='macro'))\n","\n","    y_pred.append(model.predict(tdf, num_iteration=model.best_iteration))\n","    train_pred.append(model.predict(X, num_iteration=model.best_iteration))\n","    # break\n","    \n","rmse_score = np.sqrt(metrics.mean_squared_error(y, np.argmax(oof_pred, axis=1)))\n","# want to clip and then round predictions (you can get a better performance using optimization to found the best cuts)\n","# oof_pred = np.round(np.clip(oof_pred, 0, 10)).astype(int)\n","# round_y_pred = np.round(np.clip(y_pred, 0, 10)).astype(int)\n","f1 = metrics.f1_score(y, np.argmax(oof_pred, axis=1), average = 'macro')\n","print(f'Our oof rmse score is {rmse_score}')\n","print(f'Our oof macro f1 score is {f1}')\n","\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Training until validation scores don't improve for 30 rounds.\n","[10]\ttraining's multi_logloss: 0.573777\tvalid_1's multi_logloss: 0.574401\n","[20]\ttraining's multi_logloss: 0.253718\tvalid_1's multi_logloss: 0.254803\n","[30]\ttraining's multi_logloss: 0.142524\tvalid_1's multi_logloss: 0.144114\n","[40]\ttraining's multi_logloss: 0.100991\tvalid_1's multi_logloss: 0.103088\n","[50]\ttraining's multi_logloss: 0.0843597\tvalid_1's multi_logloss: 0.0870747\n","[60]\ttraining's multi_logloss: 0.0770716\tvalid_1's multi_logloss: 0.0804356\n","[70]\ttraining's multi_logloss: 0.0735432\tvalid_1's multi_logloss: 0.0777897\n","[80]\ttraining's multi_logloss: 0.0716089\tvalid_1's multi_logloss: 0.0765356\n","[90]\ttraining's multi_logloss: 0.070883\tvalid_1's multi_logloss: 0.0763297\n","[100]\ttraining's multi_logloss: 0.0709786\tvalid_1's multi_logloss: 0.0774875\n","[110]\ttraining's multi_logloss: 0.0715036\tvalid_1's multi_logloss: 0.081236\n","[120]\ttraining's multi_logloss: 0.0786979\tvalid_1's multi_logloss: 0.0915267\n","Early stopping, best iteration is:\n","[92]\ttraining's multi_logloss: 0.0704303\tvalid_1's multi_logloss: 0.0759554\n","0.9420693781993219\n","Training until validation scores don't improve for 30 rounds.\n","[10]\ttraining's multi_logloss: 0.573851\tvalid_1's multi_logloss: 0.574213\n","[20]\ttraining's multi_logloss: 0.253826\tvalid_1's multi_logloss: 0.254494\n","[30]\ttraining's multi_logloss: 0.142659\tvalid_1's multi_logloss: 0.143704\n","[40]\ttraining's multi_logloss: 0.101062\tvalid_1's multi_logloss: 0.102613\n","[50]\ttraining's multi_logloss: 0.0844172\tvalid_1's multi_logloss: 0.0865688\n","[60]\ttraining's multi_logloss: 0.0771429\tvalid_1's multi_logloss: 0.0799228\n","[70]\ttraining's multi_logloss: 0.0735507\tvalid_1's multi_logloss: 0.0769805\n","[80]\ttraining's multi_logloss: 0.0718981\tvalid_1's multi_logloss: 0.0760111\n","[90]\ttraining's multi_logloss: 0.0711393\tvalid_1's multi_logloss: 0.0757699\n","[100]\ttraining's multi_logloss: 0.0708374\tvalid_1's multi_logloss: 0.0766978\n","[110]\ttraining's multi_logloss: 0.0725457\tvalid_1's multi_logloss: 0.0800096\n","Early stopping, best iteration is:\n","[86]\ttraining's multi_logloss: 0.0710924\tvalid_1's multi_logloss: 0.0755289\n","0.9419867987977715\n","Training until validation scores don't improve for 30 rounds.\n","[10]\ttraining's multi_logloss: 0.573723\tvalid_1's multi_logloss: 0.574642\n","[20]\ttraining's multi_logloss: 0.253686\tvalid_1's multi_logloss: 0.255048\n","[30]\ttraining's multi_logloss: 0.142519\tvalid_1's multi_logloss: 0.144317\n","[40]\ttraining's multi_logloss: 0.100947\tvalid_1's multi_logloss: 0.103228\n","[50]\ttraining's multi_logloss: 0.0843403\tvalid_1's multi_logloss: 0.0871973\n","[60]\ttraining's multi_logloss: 0.0770831\tvalid_1's multi_logloss: 0.0805551\n","[70]\ttraining's multi_logloss: 0.0735396\tvalid_1's multi_logloss: 0.0776658\n","[80]\ttraining's multi_logloss: 0.0718753\tvalid_1's multi_logloss: 0.0766338\n","[90]\ttraining's multi_logloss: 0.0712132\tvalid_1's multi_logloss: 0.0766908\n","[100]\ttraining's multi_logloss: 0.0707504\tvalid_1's multi_logloss: 0.0773646\n","[110]\ttraining's multi_logloss: 0.0720751\tvalid_1's multi_logloss: 0.0806686\n","[120]\ttraining's multi_logloss: 0.0784161\tvalid_1's multi_logloss: 0.0907799\n","Early stopping, best iteration is:\n","[93]\ttraining's multi_logloss: 0.0706426\tvalid_1's multi_logloss: 0.076096\n","0.9410154693686633\n","Training until validation scores don't improve for 30 rounds.\n","[10]\ttraining's multi_logloss: 0.573736\tvalid_1's multi_logloss: 0.574411\n","[20]\ttraining's multi_logloss: 0.253689\tvalid_1's multi_logloss: 0.254858\n","[30]\ttraining's multi_logloss: 0.142498\tvalid_1's multi_logloss: 0.144174\n","[40]\ttraining's multi_logloss: 0.100925\tvalid_1's multi_logloss: 0.103112\n","[50]\ttraining's multi_logloss: 0.0843122\tvalid_1's multi_logloss: 0.0871476\n","[60]\ttraining's multi_logloss: 0.0770752\tvalid_1's multi_logloss: 0.0805794\n","[70]\ttraining's multi_logloss: 0.0735436\tvalid_1's multi_logloss: 0.0777471\n","[80]\ttraining's multi_logloss: 0.0718896\tvalid_1's multi_logloss: 0.0767629\n","[90]\ttraining's multi_logloss: 0.0713649\tvalid_1's multi_logloss: 0.079655\n","[100]\ttraining's multi_logloss: 0.0708374\tvalid_1's multi_logloss: 0.0804625\n","[110]\ttraining's multi_logloss: 0.0703545\tvalid_1's multi_logloss: 0.0842234\n","Early stopping, best iteration is:\n","[80]\ttraining's multi_logloss: 0.0718896\tvalid_1's multi_logloss: 0.0767629\n","0.9415887759185431\n","Training until validation scores don't improve for 30 rounds.\n","[10]\ttraining's multi_logloss: 0.573734\tvalid_1's multi_logloss: 0.574625\n","[20]\ttraining's multi_logloss: 0.253699\tvalid_1's multi_logloss: 0.255016\n","[30]\ttraining's multi_logloss: 0.142525\tvalid_1's multi_logloss: 0.144322\n","[40]\ttraining's multi_logloss: 0.100922\tvalid_1's multi_logloss: 0.103319\n","[50]\ttraining's multi_logloss: 0.0843126\tvalid_1's multi_logloss: 0.0873158\n","[60]\ttraining's multi_logloss: 0.0770382\tvalid_1's multi_logloss: 0.0806885\n","[70]\ttraining's multi_logloss: 0.0734941\tvalid_1's multi_logloss: 0.0777625\n","[80]\ttraining's multi_logloss: 0.0716133\tvalid_1's multi_logloss: 0.0764922\n","[90]\ttraining's multi_logloss: 0.0706233\tvalid_1's multi_logloss: 0.0762297\n","[100]\ttraining's multi_logloss: 0.070288\tvalid_1's multi_logloss: 0.0768907\n","[110]\ttraining's multi_logloss: 0.0722654\tvalid_1's multi_logloss: 0.0800408\n","[120]\ttraining's multi_logloss: 0.0849371\tvalid_1's multi_logloss: 0.0814372\n","Early stopping, best iteration is:\n","[95]\ttraining's multi_logloss: 0.0703419\tvalid_1's multi_logloss: 0.0759911\n","0.9412845658277752\n","Our oof rmse score is 0.16960011792448731\n","Our oof macro f1 score is 0.9415897264525607\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hDd5w4tweKDP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"995297e1-50ef-4492-e801-51999e89e954","executionInfo":{"status":"ok","timestamp":1590408593899,"user_tz":-540,"elapsed":3411,"user":{"displayName":"にか","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvwEOyMaawSWc32YDQCzWn--PBY05K99EBCYw_mw=s64","userId":"12243319283870198156"}}},"source":["for i in range(len(y_pred)):\n","  if(i==0):\n","    round_y_pred = y_pred[i]\n","  else:\n","    round_y_pred += y_pred[i]\n","np.array(round_y_pred).shape"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11,)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"Jj5kVblxr4dx","colab_type":"code","colab":{}},"source":["np.save('./drive/My Drive/Colab Notebooks/liverpool-ion-switching/data/sub_mlp_class_proba_scoreing.npy', y_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CyFOtGYAscRF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4a26c36c-a69a-4d4a-d70d-63e787a525f7","executionInfo":{"status":"ok","timestamp":1590408626838,"user_tz":-540,"elapsed":612,"user":{"displayName":"にか","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvwEOyMaawSWc32YDQCzWn--PBY05K99EBCYw_mw=s64","userId":"12243319283870198156"}}},"source":["oof_pred.shape"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5000000, 11)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"zaxky0gJsV4j","colab_type":"code","colab":{}},"source":["np.save('./drive/My Drive/Colab Notebooks/liverpool-ion-switching/data/oof_mlp_class_proba_scoreing.npy', oof_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TZ0aLuZysh2y","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}